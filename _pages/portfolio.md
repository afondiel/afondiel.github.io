---
permalink: /portfolio/
title: "Portfolio"
toc: true
toc_label: "Table of Contents"
toc_icon: "bookmark"
---
<!-- *Updated: 01/24/2025* -->

Explore my cutting-edge computer vision solutions addressing real-world challenges in smart industries such as autonomous systems, healthcare, agriculture, and more. 

## Computer Vision Real-World Applications

### Classification Stack: CNN, ViT
<!--classification Stack: CNN, ViT-->

**CIFAR-10 Image Classification**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/computer-vision-challenge/blob/main/L1_02_CIFAR_10_Image_Classification/notebooks/CIFAR_10_Image_Classification.ipynb) 

Using Convolutional Neural Networks (CNNs) to classify images of different types of objects from the CIFAR-10 dataset.

### Object Detection Stack: 2D, 3D
<!--Object Detection Stack: 2D, 3D, 4D-->

**2D Object Detection with YOLOv5**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/computer-vision-challenge/blob/main/L1_03_Object_Detection_with_YOLOv_/notebooks/Object_Detection_with_YOLOv5.ipynb) 

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="/assets/images/portfolio_assets/the-beatles.png" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

<!-- ### Segmentation Stack: semantic, instance, panoptic
<!--Segmentation Stack: semantic, instance, panoptic-->

<!-- [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/computer-vision-challenge)   -->

### Multimodality (VLMs: GANs, VAEs, Diffusers ...)

<!--Multimodality (VLMs: GANs, VAEs, Diffusers ...-->
**AI Assisted Image Editing and Manipulation**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/computer-vision-challenge) [![Demo on HF Spaces](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm-dark.svg)](https://huggingface.co/spaces/afondiel/image-colorizer-deoldify)

This is an AI Image Editing and Manipulation tool for Image creation, editing and manipulation.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/computer-vision-challenge/blob/main/L2_06_AI_Assisted_Image_Editing_and_Manipulation/docs/pipeline-last.png?raw=true" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

**Multimodal AI Storyteller**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/computer-vision-challenge/tree/main/L2_05_AI_Driven_Image_Captioning_and_Storytelling) 

Generate text and audio stories from image.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/computer-vision-challenge/blob/main/L2_05_AI_Driven_Image_Captioning_and_Storytelling/docs/storyteller_pipeline.png?raw=true
" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### Motion & Video Analysis: Tracking & Flow
<!--Motion & Video Analysis: Tracking & Flow-->

**2D Object Tracking with OpenCV and Deep Learning**
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/computer-vision-challenge/tree/main/L1_06_2D_Object_Tracking) 

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/computer-vision-challenge/blob/main/L1_06_2D_Object_Tracking/goturn.jpg?raw=true" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

## Perception

### 2D Object Detection with YOLO for Autonomous Vehicles

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/lab/notebooks/02-2d-object-det/2d-object-detection-yolov3-keras.ipynb)

Apply the [YOLO (You Only Look Once)](https://docs.ultralytics.com/) model series to detect and classify objects such as pedestrians, vehicles, and traffic signs in real-time. It uses real-world camera and LIDAR data from Lyft 3D Object Detection [dataset](https://www.kaggle.com/competitions/3d-object-detection-for-autonomous-vehicles) for autonomous vehicles.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/docs/02-2d-object-det/2d-obj-det-yolo-cover.png?raw=true" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### Road Segmentation with Fully Convolutional Networks (FCN)

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/lab/notebooks/01-Road-Seg/road-segmentation-fcn-tf.ipynb)

Implement an Fully Convolutional Networks ([FCN](https://arxiv.org/abs/1411.4038)) model to perform pixel-wise classification, enabling the vehicle to distinguish drivable road areas from obstacles. It gets real-world visual data from [KITTI Dataset](https://www.cvlibs.net/datasets/kitti/).

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="/assets/images/portfolio_assets/fcn_road_seg_in_out.png" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### Realtime Multi-Object Tracking with DeepSORT

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/lab/notebooks/03-object-tracking/object-tracking-deep-sort.ipynb)

Integrate the [DeepSORT](https://arxiv.org/pdf/1703.07402) model to track the trajectory of detected objects across video frames, maintaining consistent identification.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://camo.githubusercontent.com/8956282c16223fa825b6d680ebc724d781c989a24e74aa941ce2c3f6f5d44677/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f76322f726573697a653a6669743a313430302f302a2d5332456b7547686b503974703949742e4a5047" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### 3D Object Detection with SFA3D and KITTI
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/lab/notebooks/06-3d-obj-det/3d-object-detection-sfa3d.ipynb)

Utilize the [SFA3D](https://arxiv.org/pdf/2001.03343) model to detect objects in 3D space using LiDAR data from [KITTI](https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d) dataset, crucial for understanding the vehicle's surroundings.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="
https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/raw/main/docs/06-3d-obj-det/3d-object-detection-cover.png
" style="max-width: 100%; height: auto;" width="1280" height="720"></p>


### 3D Data Visualization and Homogeneous Transformations 

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/lab/notebooks/04-3d-data-viz/3d-data-visualization-kitti-lidar.ipynb )

Visualize and manipulate 3D point cloud data from LiDAR sensors ([KITTI](https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d) dataset), applying homogeneous transformations to align data from multiple sensors.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/raw/main/docs/04-3d-data-viz/3d-data-viz-cover.png" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### Camera to Bird's Eye View Projection with UNetXST

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/lab/notebooks/07-UNetXST/unetxst-camera-to-bird-s-eye-view.ipynb)

Develop a model to transform camera images into a bird's eye view, aiding in better spatial understanding for navigation.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/raw/main/docs/07-UNetXST/07-camera-to-birds-eye-view-using-unetxst-cover.png" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### Multi-Task Learning with Multi-Task Attention Network (MTAN)

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/blob/main/lab/notebooks/05-MTAN/mtan-multi-task-attention-network.ipynb)

Implement a Multi-Task Attention Network ([MTAN](https://arxiv.org/pdf/1803.10704)) on [CityScapes](https://www.cityscapes-dataset.com/) Dataset, to simultaneously perform tasks like road segmentation and object detection, improving computational efficiency.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/Self-Driving-Cars-Perception-and-Deep-Learning-Free-Course-freeCodeCamp/raw/main/docs/05-MTAN/MTAN-cover.png" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### Multimodal Sensor Fusion with GPS, IMU, and LiDAR for Vehicule Localization.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/diesimo-ai/self-driving-car-projects/tree/main/p5-self-driving-vehicle-state-estimation-on-roadway)

This project involved integrating data from multiple sensors to accurately determine a vehicle's position and motion on the roadway. The system uses techniques such as Kalman filtering to combine inputs from GPS, IMU, and LiDAR, enhancing the precision of state estimation critical for autonomous driving applications.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/diesimo-ai/self-driving-car-projects/blob/main/p5-self-driving-vehicle-state-estimation-on-roadway/doc/full-state-estimation-pipeline.png?raw=true" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

**Additional Resources:** [Linear/Non Linear KF Implementation](https://github.com/afondiel/computer-science-notebook/blob/master/core/fundamentals/signal-processing/sp-algorithms/Kalman_filter_linear_nonlinear.ipynb).

### Depth Perception for Obstacle Detection on the Road

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/Self-Driving-Cars-Specialization/blob/7a3866e06e9e0e9ff9f010fd44e635e385f4514b/Course3-Visual-Perception-for-Self-Driving-Cars/resources/w1/lab/Applying%20Stereo%20Depth%20to%20a%20Driving%20Scenario%20(practice%20assignment).ipynb)

Implemented stereo depth estimation using Python and OpenCV on CARLA simulator images to calculate collision distances in a driving scenario.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="/assets/images/portfolio_assets/depth_cover.png" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

**Additional Resources:** Learn core concepts [here](https://github.com/afondiel/Self-Driving-Cars-Specialization/blob/7a3866e06e9e0e9ff9f010fd44e635e385f4514b/Course3-Visual-Perception-for-Self-Driving-Cars/course3-w1-notes.md).

### Visual Odometry (VO) for Self-Driving Car Location

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/diesimo-ai/self-driving-car-projects/tree/main/p6-visual-odometry-for-localization)

This is a visual odometry system that estimates the vehicle's trajectory using realtime visual data captured by its (monocular) camera.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/diesimo-ai/self-driving-car-projects/blob/main/p6-visual-odometry-for-localization/doc/pair-imgs-pxls.png?raw=true" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

<!-- Visual DMS -->
<!-- Surround-view perception (Valeo OmniDet)-->
<!-- Multi-camera-fusion: 360-degree fusion -->

## Edge AI

**Edge AI** involves processing data locally on devices, reducing inference cost, offering faster decision-making, and enhanced security.

- Further Reading: [The Next AI Frontier is at the Edge](https://afondiel.github.io/posts/the-next-ai-frontier-is-at-the-edge/)
- Learning Resources: [Curated Edge AI Technical Guides](https://github.com/afondiel/computer-science-notebook/tree/master/core/systems/edge-computing/edge-ai/)

<!--Deploy with TensorRT on Jetson Nano-->

### Real-time Segmentation Deployment with Qualcomm AI Hub 

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/computer-science-notebook/blob/master/core/systems/edge-computing/edge-ai/lab/examples/deploy-with-qualcomm/notebooks/Deploy_RT_Segmentation_Model_On_Real_Device.ipynb) [![Open notebook in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/afondiel/afondiel.github.io/blob/main/assets/images/blog-posts/edge-ai/101/lab/Deploy_RT_Segmentation_Model_On_Real_Device.ipynb)

<!-- STAR Framework => Result/value - Driven-->
This case study demonstrates how to deploy a semantic segmentation model optimized for edge devices using [Qualcomm AI Hub](https://aihub.qualcomm.com/). The example leverages **FFNet**, a model tailored for efficient edge-based semantic segmentation, tested on the [Cityscapes dataset](https://www.cityscapes-dataset.com/).

**Industry Applications**: Autonomous Driving, Augmented Reality, and Mobile Robotics

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="/assets/images/blog-posts/edge-ai/101/ffnet-seg.png" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

## Case Studies

### Autonomous Systems (Self-Driving Cars/ADAS, Robotics, UAVs)

**Self-Driving Car Environment Perception**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/diesimo-ai/self-driving-car-projects/tree/main/p7-self-driving-car-environment-perception)

Self-Driving Car foundational perception stack, which extracts useful information from its surroudings and perform complex tasks in order to drive safely through the world

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/diesimo-ai/self-driving-car-projects/blob/main/p7-self-driving-car-environment-perception/doc/final-project-segNet.png?raw=true" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

**End-to-End Self-Driving Car Behavioral Cloning**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/diesimo-ai/self-driving-car-behavioral-cloning/tree/master)

End-to-End self-driving car behavioral cloning implementation based on NVIDIA End-to-End Learning [paper](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) using computer vision, deep learning,  and realtime visual data from [Udacity Self-Driving Car simulator](https://github.com/udacity/self-driving-car-sim).

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/diesimo-ai/self-driving-car-behavioral-cloning/blob/master/docs/img/autonomous-mode.png?raw=true" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

### Smart Cities 

**⚡ SmartMeterSim: IoT Smart Meter Simulation**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/afondiel/SmartMeterSim) [![Demo on HF Spaces](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm-dark.svg)](https://huggingface.co/spaces/afondiel/SmartMeterSim)

⚡ SmartMeterSim is a production-ready IoT solution for real-time energy monitoring and optimization for smart grids, buildings, and Edge-to-Cloud applications.

<p style="text-align: center;"> <img loading="lazy" decoding="async" class="aligncenter size-full" src="https://github.com/afondiel/SmartMeterSim/blob/main/resources/demo/cover.png?raw=true?" style="max-width: 100%; height: auto;" width="1280" height="720"></p>

## Resources: Edge AI & Computer Vision 

- [Edge AI Engineering](https://github.com/afondiel/edge-ai-engineering)
- [Edge Vision](https://github.com/afondiel/edge-vision)
- [Edge AI Model Zoo](https://github.com/afondiel/Edge-AI-Model-Zoo)
- [Edge AI Platforms](https://github.com/afondiel/Edge-AI-Platforms)
- [Edge AI Benchmarks & Evaluation](https://github.com/afondiel/Edge-AI-Model-Zoo/blob/main/model-eval-benchmarking-guide.md)
- [Edge AI Deployment Stack](https://github.com/afondiel/computer-science-notebook/tree/master/core/systems/edge-computing/edge-ai/concepts/deployment)
- [Edge AI Qualcomm Stack](https://www.qualcomm.com/developer/artificial-intelligence)
- [Edge AI Ecosystem](https://github.com/afondiel/computer-science-notebook/tree/master/core/systems/edge-computing/edge-ai/industry-applications)
- [Edge AI Books](https://github.com/afondiel/cs-books/tree/main/edge)
- [Edge AI Blog](https://afondiel.github.io/posts/)

- [⬆️ Back to the Top ⬆️](#computer-vision-challenge-)

<!-- ## Resources -->
<!--Add Resources section for Magnet-->
<!-- magnets: whitepapers, PoC-20 access, free trial toolkit: atedge ... -->
<!--Edge AI Deployment Checklist-->
<!-- a free PDF: "Edge AI Deployment Checklist: Optimize Models for Any Industry." -->